#!/usr/bin/env python3
import os
import sys
import requests
import urllib.parse
import re
import concurrent.futures
import socket
import ssl
import xml.etree.ElementTree as ET
from bs4 import BeautifulSoup
from typing import List, Dict, Set, Optional
import logging
import argparse
from datetime import datetime

class WebVulnerabilityScanner:
    def __init__(self, target_url: str, max_threads: int = 10):
        self.target_url = target_url
        self.max_threads = max_threads
        self.visited_urls: Set[str] = set()
        self.forms: List[Dict] = []
        self.vulnerabilities: List[Dict] = []
        
        # Configure logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('scanner.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
        # Common payload lists
        self.xss_payloads = [
            '<script>alert("XSS")</script>',
            '"><script>alert("XSS")</script>',
            '<img src=x onerror=alert("XSS")>',
            '{{7*7}}',
            '${7*7}',
            "' OR '1'='1"
        ]
        
        self.sqli_payloads = [
            "' OR '1'='1",
            "' UNION SELECT NULL--",
            "admin' --",
            "' OR 1=1--",
            "'; DROP TABLE users--"
        ]
        
        self.lfi_payloads = [
            "../../../etc/passwd",
            "../../windows/win.ini",
            "..%2F..%2F..%2Fetc%2Fpasswd",
            "/etc/passwd%00",
            "../../../../../../../../etc/passwd"
        ]

    def scan(self):
        """Main scanning function that coordinates all security checks"""
        self.logger.info(f"Starting scan of {self.target_url}")
        start_time = datetime.now()

        try:
            # Basic server information gathering
            self.check_server_info()
            
            # Crawl the website to find all accessible URLs
            discovered_urls = self.crawl_website(self.target_url)
            
            # Perform security checks
            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_threads) as executor:
                # SSL/TLS checks
                executor.submit(self.check_ssl_security)
                
                # Check security headers
                executor.submit(self.check_security_headers)
                
                # Scan for vulnerabilities on each discovered URL
                for url in discovered_urls:
                    executor.submit(self.check_xss_vulnerability, url)
                    executor.submit(self.check_sql_injection, url)
                    executor.submit(self.check_lfi_vulnerability, url)
                    executor.submit(self.check_open_redirects, url)
                
                # Check forms for CSRF
                forms = self.extract_forms(self.target_url)
                for form in forms:
                    executor.submit(self.check_csrf_vulnerability, form)

        except Exception as e:
            self.logger.error(f"Error during scan: {str(e)}")
            raise

        finally:
            end_time = datetime.now()
            duration = end_time - start_time
            self.logger.info(f"Scan completed in {duration}")
            self.generate_report()

    def check_server_info(self):
        """Gather basic server information"""
        try:
            response = requests.head(self.target_url)
            server = response.headers.get('Server', 'Not disclosed')
            powered_by = response.headers.get('X-Powered-By', 'Not disclosed')
            
            self.logger.info(f"Server: {server}")
            self.logger.info(f"Powered by: {powered_by}")
            
            self.vulnerabilities.append({
                'type': 'information_disclosure',
                'description': f'Server information disclosed: {server}, {powered_by}',
                'severity': 'Low'
            })
            
        except requests.RequestException as e:
            self.logger.error(f"Error checking server info: {str(e)}")

    def check_ssl_security(self):
        """Check SSL/TLS configuration"""
        try:
            hostname = urllib.parse.urlparse(self.target_url).netloc
            context = ssl.create_default_context()
            with socket.create_connection((hostname, 443)) as sock:
                with context.wrap_socket(sock, server_hostname=hostname) as ssock:
                    cert = ssock.getpeercert()
                    
                    # Check certificate expiration
                    not_after = datetime.strptime(cert['notAfter'], '%b %d %H:%M:%S %Y %Z')
                    if not_after < datetime.now():
                        self.vulnerabilities.append({
                            'type': 'ssl_certificate',
                            'description': 'SSL certificate has expired',
                            'severity': 'High'
                        })
                    
                    # Check protocol version
                    protocol_version = ssock.version()
                    if protocol_version in ['SSLv2', 'SSLv3', 'TLSv1', 'TLSv1.1']:
                        self.vulnerabilities.append({
                            'type': 'ssl_protocol',
                            'description': f'Weak SSL/TLS protocol version: {protocol_version}',
                            'severity': 'High'
                        })
                        
        except Exception as e:
            self.logger.error(f"Error checking SSL security: {str(e)}")

    def check_security_headers(self):
        """Check for missing security headers"""
        try:
            response = requests.get(self.target_url)
            headers = response.headers
            
            security_headers = {
                'Strict-Transport-Security': 'Missing HSTS header',
                'X-Frame-Options': 'Missing X-Frame-Options header',
                'X-Content-Type-Options': 'Missing X-Content-Type-Options header',
                'Content-Security-Policy': 'Missing Content Security Policy',
                'X-XSS-Protection': 'Missing XSS Protection header'
            }
            
            for header, message in security_headers.items():
                if header not in headers:
                    self.vulnerabilities.append({
                        'type': 'missing_security_header',
                        'description': message,
                        'severity': 'Medium'
                    })
                    
        except requests.RequestException as e:
            self.logger.error(f"Error checking security headers: {str(e)}")

    def crawl_website(self, url: str) -> Set[str]:
        """Crawl website to discover URLs"""
        if url in self.visited_urls:
            return set()
        
        self.visited_urls.add(url)
        discovered_urls = {url}
        
        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Find all links
            for link in soup.find_all('a'):
                href = link.get('href')
                if href:
                    absolute_url = urllib.parse.urljoin(url, href)
                    if absolute_url.startswith(self.target_url) and absolute_url not in self.visited_urls:
                        discovered_urls.update(self.crawl_website(absolute_url))
                        
        except requests.RequestException as e:
            self.logger.error(f"Error crawling {url}: {str(e)}")
            
        return discovered_urls

    def check_xss_vulnerability(self, url: str):
        """Check for XSS vulnerabilities"""
        try:
            for payload in self.xss_payloads:
                # Test URL parameters
                parsed_url = urllib.parse.urlparse(url)
                params = urllib.parse.parse_qs(parsed_url.query)
                
                for param in params:
                    test_url = url.replace(f"{param}={params[param][0]}", f"{param}={payload}")
                    response = requests.get(test_url)
                    
                    if payload in response.text:
                        self.vulnerabilities.append({
                            'type': 'xss',
                            'url': url,
                            'parameter': param,
                            'payload': payload,
                            'severity': 'High'
                        })
                        
        except requests.RequestException as e:
            self.logger.error(f"Error checking XSS vulnerability: {str(e)}")

    def check_sql_injection(self, url: str):
        """Check for SQL injection vulnerabilities"""
        try:
            for payload in self.sqli_payloads:
                # Test URL parameters
                parsed_url = urllib.parse.urlparse(url)
                params = urllib.parse.parse_qs(parsed_url.query)
                
                for param in params:
                    test_url = url.replace(f"{param}={params[param][0]}", f"{param}={payload}")
                    response = requests.get(test_url)
                    # Look for SQL error messages
                    sql_errors = [
                        "SQL syntax",
                        "mysql_fetch",
                        "ORA-",
                        "PostgreSQL",
                        "SQLite/JDBCDriver"
                    ]
                    for error in sql_errors:
                        if error.lower() in response.text.lower():
                            self.vulnerabilities.append({
                                'type': 'sql_injection',
                                'url': url,
                                'parameter': param,
                                'payload': payload,
                                'severity': 'High'
                            })
                            
        except requests.RequestException as e:
            self.logger.error(f"Error checking SQL injection vulnerability: {str(e)}")

    def check_lfi_vulnerability(self, url: str):
        """Check for Local File Inclusion vulnerabilities"""
        try:
            for payload in self.lfi_payloads:
                # Test URL parameters
                parsed_url = urllib.parse.urlparse(url)
                params = urllib.parse.parse_qs(parsed_url.query)
                
                for param in params:
                    test_url = url.replace(f"{param}={params[param][0]}", f"{param}={payload}")
                    response = requests.get(test_url)
                    
                    # Look for common file content indicators
                    lfi_indicators = [
                        "root:x:",
                        "[boot loader]",
                        "daemon:",
                        "BUILD_ID"
                    ]
                    
                    for indicator in lfi_indicators:
                        if indicator in response.text:
                            self.vulnerabilities.append({
                                'type': 'lfi',
                                'url': url,
                                'parameter': param,
                                'payload': payload,
                                'severity': 'High'
                            })
                            
        except requests.RequestException as e:
            self.logger.error(f"Error checking LFI vulnerability: {str(e)}")

    def check_open_redirects(self, url: str):
        """Check for open redirect vulnerabilities"""
        redirect_payloads = [
            'https://evil.com',
            '//evil.com',
            '////evil.com',
            'https:evil.com'
        ]
        try:
            parsed_url = urllib.parse.urlparse(url)
            params = urllib.parse.parse_qs(parsed_url.query)
            redirect_params = ['redirect', 'url', 'next', 'redir', 'return', 'return_url']
            
            for param in params:
                if param.lower() in redirect_params:
                    for payload in redirect_payloads:
                        test_url = url.replace(f"{param}={params[param][0]}", f"{param}={payload}")
                        response = requests.get(test_url, allow_redirects=False)
                        
                        if response.status_code in [301, 302, 303, 307, 308]:
                            location = response.headers.get('Location', '')
                            if any(evil in location.lower() for evil in ['evil.com']):
                                self.vulnerabilities.append({
                                    'type': 'open_redirect',
                                    'url': url,
                                    'parameter': param,
                                    'payload': payload,
                                    'severity': 'Medium'
                                })
                                
        except requests.RequestException as e:
            self.logger.error(f"Error checking open redirect vulnerability: {str(e)}")

    def extract_forms(self, url: str) -> List[Dict]:
        """Extract forms from the webpage"""
        try:
            response = requests.get(url)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            forms = []
            for form in soup.find_all('form'):
                form_info = {
                    'action': form.get('action', ''),
                    'method': form.get('method', 'get'),
                    'inputs': []
                }
                
                for input_field in form.find_all(['input', 'textarea']):
                    form_info['inputs'].append({
                        'name': input_field.get('name', ''),
                        'type': input_field.get('type', 'text')
                    })
                    
                forms.append(form_info)
                
            return forms
            
        except requests.RequestException as e:
            self.logger.error(f"Error extracting forms: {str(e)}")
            return []

    def check_csrf_vulnerability(self, form: Dict):
        """Check for CSRF vulnerabilities in forms"""
        try:
            # Check for CSRF token
            has_csrf_token = False
            csrf_fields = ['csrf', 'token', '_token', 'csrf_token']
            
            for input_field in form['inputs']:
                if any(csrf in input_field['name'].lower() for csrf in csrf_fields):
                    has_csrf_token = True
                    break
                    
            if not has_csrf_token and form['method'].lower() == 'post':
                self.vulnerabilities.append({
                    'type': 'csrf',
                    'form_action': form['action'],
                    'description': 'Form missing CSRF token',
                    'severity': 'Medium'
                })
                
        except Exception as e:
            self.logger.error(f"Error checking CSRF vulnerability: {str(e)}")

    def generate_report(self):
        """Generate a detailed XML report of findings"""
        try:
            root = ET.Element("vulnerability_report")
            ET.SubElement(root, "target_url").text = self.target_url
            ET.SubElement(root, "scan_date").text = datetime.now().isoformat()
            
            findings = ET.SubElement(root, "findings")
            
            # Group vulnerabilities by severity
            severity_groups = {'High': [], 'Medium': [], 'Low': []}
            for vuln in self.vulnerabilities:
                severity_groups[vuln['severity']].append(vuln)
            
            # Add vulnerabilities to report
            for severity in severity_groups:
                severity_elem = ET.SubElement(findings, f"{severity.lower()}_severity")
                for vuln in severity_groups[severity]:
                    vuln_elem = ET.SubElement(severity_elem, "vulnerability")
                    # Continuing from the generate_report method...
                    for key, value in vuln.items():
                        ET.SubElement(vuln_elem, key).text = str(value)

                # Add summary statistics
                summary = ET.SubElement(root, "summary")
                ET.SubElement(summary, "total_vulnerabilities").text = str(len(self.vulnerabilities))
                for severity in severity_groups:
                    ET.SubElement(summary, f"total_{severity.lower()}_severity").text = str(
                        len(severity_groups[severity]))

                # Write report to file
                tree = ET.ElementTree(root)
                report_filename = f"vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xml"
                tree.write(report_filename, encoding='utf-8', xml_declaration=True)

                self.logger.info(f"Report generated: {report_filename}")

                # Also generate a human-readable summary
                self._generate_text_summary(severity_groups)

        except Exception as e:
            self.logger.error(f"Error generating report: {str(e)}")

    def _generate_text_summary(self, severity_groups: Dict[str, List[Dict]]):
        """Generate a human-readable summary of findings"""
        try:
            summary_filename = f"vulnerability_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

            with open(summary_filename, 'w') as f:
                f.write("Web Vulnerability Scan Summary\n")
                f.write("=" * 30 + "\n\n")
                f.write(f"Target URL: {self.target_url}\n")
                f.write(f"Scan Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

                f.write("Summary of Findings:\n")
                f.write("-" * 20 + "\n")
                f.write(f"Total Vulnerabilities: {len(self.vulnerabilities)}\n")
                for severity in severity_groups:
                    f.write(f"Total {severity} Severity: {len(severity_groups[severity])}\n")

                f.write("\nDetailed Findings:\n")
                f.write("=" * 20 + "\n\n")

                for severity in severity_groups:
                    if severity_groups[severity]:
                        f.write(f"\n{severity} Severity Vulnerabilities:\n")
                        f.write("-" * 30 + "\n")
                        for vuln in severity_groups[severity]:
                            f.write(f"\nType: {vuln.get('type', 'Unknown')}\n")
                            for key, value in vuln.items():
                                if key not in ['type', 'severity']:
                                    f.write(f"{key.capitalize()}: {value}\n")
                            f.write("-" * 20 + "\n")

                f.write("\nRecommendations:\n")
                f.write("=" * 20 + "\n")
                self._write_recommendations(f)

            self.logger.info(f"Summary report generated: {summary_filename}")

        except Exception as e:
            self.logger.error(f"Error generating text summary: {str(e)}")

    def _write_recommendations(self, file_handle):
        """Write security recommendations based on findings"""
        recommendations = {
            'xss': 'Implement proper input validation and output encoding. Consider using Content Security Policy (CSP).',
            'sql_injection': 'Use prepared statements or ORM. Never concatenate user input directly into SQL queries.',
            'lfi': 'Implement proper file path validation and restrict file access to specific directories.',
            'csrf': 'Implement CSRF tokens for all forms and validate them server-side.',
            'open_redirect': 'Implement a whitelist of allowed redirect URLs and validate all redirects.',
            'missing_security_header': 'Configure proper security headers including HSTS, CSP, and X-Frame-Options.',
            'ssl_certificate': 'Ensure SSL certificates are valid and up to date. Use modern TLS protocols.',
            'information_disclosure': 'Minimize server information disclosure in headers and error messages.'
        }

        vuln_types = set(vuln['type'] for vuln in self.vulnerabilities)

        for vuln_type in vuln_types:
            if vuln_type in recommendations:
                file_handle.write(f"\n{vuln_type.upper()}:\n")
                file_handle.write(recommendations[vuln_type] + "\n")


def main():
    """Main function to run the scanner"""
    parser = argparse.ArgumentParser(description='Web Vulnerability Scanner')
    parser.add_argument('url', help='Target URL to scan')
    parser.add_argument('--threads', type=int, default=10, help='Number of threads to use')
    parser.add_argument('--output', help='Output directory for reports', default='.')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose output')

    args = parser.parse_args()

    # Configure logging based on verbosity
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level)

    try:
        # Create output directory if it doesn't exist
        os.makedirs(args.output, exist_ok=True)

        # Initialize and run scanner
        scanner = WebVulnerabilityScanner(args.url, args.threads)
        scanner.scan()

    except Exception as e:
        logging.error(f"Error during scan: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()

# Example usage:
# python web_vulnerability_scanner.py https://example.com --threads 15 --output ./scan_results --verbose